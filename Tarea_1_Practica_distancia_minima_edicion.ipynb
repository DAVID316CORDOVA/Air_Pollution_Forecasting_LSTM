{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAVID316CORDOVA/Air_Pollution_Forecasting_LSTM/blob/master/Tarea_1_Practica_distancia_minima_edicion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aspectos generales"
      ],
      "metadata": {
        "id": "9qAqmgDhT_d4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El autocorrector de errores ortograficos se usa todos los días en los computadores y celulares. En este taller, exploramos alguno de los principales aspectos de como están construidos con el Procesamiento de Lenguaje Natural y la distancia de edición mínima. No se revisan caracteristicas de despliegue o de ingeniería de sistemas para la construcción de una aplicación.\n",
        "\n",
        "Los objetivos del taller son:\n",
        "1. Implementar el conteo de palabras dado un corpus.\n",
        "2. Obtener la probabilidad por palabra dado un corpus.\n",
        "3. Manipular cadenas de texto.\n",
        "4. Hacer filtos de cadenas de texto.\n",
        "5. Implementar la Distancia de edición minima para comparar cadenas de texto y encotrar el paso optimo de edición.\n",
        "6. Entender como funciona a la programación dinamica aplicada al PLN."
      ],
      "metadata": {
        "id": "q4z7HfJkUEZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ejemplo de que es un autocorrector\n",
        "\n",
        "El autocorrector de ortografía es como se muestra en la Figura 1\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1lXZbG4KjkrPyQ5JtzVaMKrQh86SY6xVf\">"
      ],
      "metadata": {
        "id": "edeph4uQcJm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Distancias de edición\n",
        "En este taller se muestra la implementación de un autocorrect que esta a una (1) o dos (2) distancias de edición\n",
        "\n",
        "Un distación de edición consiste en una de las siguientes opciones:\n",
        "\n",
        "\n",
        "*   Borrar: oír => \"ír, oí, or\"\n",
        "*   intercambio de dos letras adjacentes: comer => \"ocmer, comre...\"\n",
        "\n",
        "*   Replazar: fuego => \"juego, luego, ruego...\"\n",
        "*   Insertar, agregar una letra: ir => \"ire, ira, ird, air...\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o0xdipUd8nT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bayes Rules"
      ],
      "metadata": {
        "id": "zC1wx2WB_Imw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo es hacer una autocorrección sugerida por la probabilidad dado un corpus:\n",
        "\n",
        "$$P(c|w) = \\frac{P(w|c)\\times P(c)}{P(w)} \\tag{Eqn-1}$$\n",
        "\n",
        "La ecuación 1 describe la [Bayes Rule](https://en.wikipedia.org/wiki/Bayes%27_theorem)"
      ],
      "metadata": {
        "id": "oJSzPHNf-6bi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocesamiento"
      ],
      "metadata": {
        "id": "QPLvxAXZ_xPE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FHwFScHMT3Hi"
      },
      "outputs": [],
      "source": [
        "#se importan las librerias requeridas\n",
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cargue del corpus\n",
        "\n",
        "def process_data(file_name):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        A file_name which is found in your current directory. You just have to read it in.\n",
        "    Output:\n",
        "        words: a list containing all the words in the corpus (text file you read) in lower case.\n",
        "    \"\"\"\n",
        "    words = [] # return this variable correctly\n",
        "\n",
        "    #Open the file, read its contents into a string variable\n",
        "    with open(file_name, \"r\") as file:\n",
        "        texto = file.read()\n",
        "\n",
        "    # convert all letters to lower case\n",
        "    texto = texto.lower()\n",
        "    #Convert every word to lower case and return them in a list.\n",
        "    words = re.findall(\"\\w+\", texto)\n",
        "\n",
        "    return words"
      ],
      "metadata": {
        "id": "VWGr-4y6_5k8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = process_data(\"/content/elquijote.txt\")\n",
        "print(\"el numero de palabras es: {}\".format(len(words)))\n",
        "vocab = set(words)\n",
        "print(\"el vocabulario (numero de palabras unicas) es de: {}\".format(len(vocab)))\n",
        "print(\"algunas de las palabras son: {}\".format(words[500:550]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dav-hQyABdi4",
        "outputId": "89411ec0-52de-427e-a67d-ce8436759d24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el numero de palabras es: 384442\n",
            "el vocabulario (numero de palabras unicas) es de: 23631\n",
            "algunas de las palabras son: ['día', 'de', 'la', 'data', 'desta', 'nuestra', 'cédula', 'so', 'pena', 'que', 'la', 'persona', 'o', 'personas', 'que', 'sin', 'tener', 'vuestro', 'poder', 'lo', 'imprimiere', 'o', 'vendiere', 'o', 'hiciere', 'imprimir', 'o', 'vender', 'por', 'el', 'mesmo', 'caso', 'pierda', 'la', 'impresión', 'que', 'hiciere', 'con', 'los', 'moldes', 'y', 'aparejos', 'della', 'y', 'más', 'incurra', 'en', 'pena', 'de', 'cincuenta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Diccionario"
      ],
      "metadata": {
        "id": "7UpbRNPCDBqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear el disccionario, donde las llaves son las palabras y los valores es el numero de veces que la palabra aparece\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1bi25J511Uaw4Gwr_Z7L6FUII5zbmP6I_\">"
      ],
      "metadata": {
        "id": "IMxkm1uGEOBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(word_l):\n",
        "    '''\n",
        "    Input:\n",
        "        word_l: a set of words representing the corpus.\n",
        "    Output:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    '''\n",
        "\n",
        "    word_count_dict = {}  # Creamos un diccionario vacío para almacenar la frecuencia de cada palabra\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    for word in word_l:  # Iteramos por cada palabra en el conjunto de palabras\n",
        "        if word in word_count_dict:\n",
        "            word_count_dict[word] += 1  # Si la palabra ya está en el diccionario, incrementamos su contador\n",
        "        else:\n",
        "            word_count_dict[word] = 1   # Si es la primera vez que vemos la palabra, la agregamos con valor 1\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return word_count_dict"
      ],
      "metadata": {
        "id": "1mK2PFpmFz9R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_dict = get_count(words)\n",
        "print(\"existen {} keys\".format(len(word_count_dict)))\n",
        "print(\"las veces que se menciona dulcinea: {}\".format(word_count_dict.get(\"dulcinea\", 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YabmQkSF99s",
        "outputId": "733f4cf4-db77-41f9-c234-7ecfac18080f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "existen 23631 keys\n",
            "las veces que se menciona dulcinea: 282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calcular las probabilidades"
      ],
      "metadata": {
        "id": "yqJA_YBGG-tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado el diccionario, se deben calcular las probabilidades que una palabra sea seleccionada de forma aleatoria dado el corpus\n",
        "\n",
        "$$P(w_i) = \\frac{C(w_i)}{M} \\tag{Eqn-2}$$\n",
        "\n",
        "Donde $C(w_i)$ es el numero de veces $w_i$ aparece en el corpus.\n",
        "\n",
        "$M$ es el numero total de palabras en el corpus\n",
        "\n",
        "Por ejemplo, la probabilidad que la palabra nlp aparece en la oración \"estoy en la clase de nlp\" es\n",
        "\n",
        "$$P(am) = \\frac{C(w_i)}{M} = \\frac {2}{12} \\tag{Eqn-3}.$$"
      ],
      "metadata": {
        "id": "_8K_bPcrHTjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probs(word_count_dict):\n",
        "    '''\n",
        "    Input:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    Output:\n",
        "        probs: A dictionary where keys are the words and the values are the probability that a word will occur.\n",
        "    '''\n",
        "    probs = {}  # return this variable correctly\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # get the total count of words for all words in the dictionary\n",
        "\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return probs"
      ],
      "metadata": {
        "id": "tjgzyJsYG6tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = get_probs(word_count_dict)\n",
        "print(\"numero de total de palabras: {}\".format(len(probs)))\n",
        "print(\"P(dulcinea) es: {:.4f}\".format(probs[\"dulcinea\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtpGz707Iy33",
        "outputId": "fb2f9914-d0db-4662-c2fd-0636f3e27050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numero de total de palabras: 23631\n",
            "P(dulcinea) es: 0.0007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Manipulación de cadenas de caracteres - Distancias de edición:"
      ],
      "metadata": {
        "id": "LAuMMruGJ3uL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##List comprehensions\n",
        "La manipulación de cadenas de caracteres y lista en python se sugiere realizar a traves de funciones denominadas [list comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)\n",
        "\n",
        "Python List Comprehensions es un loop embebido dentro de una estructura de lista, colapsando muchas lineas de codigos en una sola.\n",
        "\n",
        "La figura 2 muesta un loop tradicional y una list comprehension\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1sSmz8YIMFhp4jopHE1Nfeq2vrjmi7R8X\"/>\n",
        "**Figura 2**\n"
      ],
      "metadata": {
        "id": "0mlQfiKILAPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Borrar"
      ],
      "metadata": {
        "id": "CWb2iijjPL9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instrucciones**\n",
        "Crear la función delete_letter()\n",
        "\n",
        "Por ejemplo, dada la palabra **oir**, retornar un conjuto de {\"ir\", \"oi\", \"or\"}"
      ],
      "metadata": {
        "id": "bDZjwkAUPlED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 1**\n",
        "Dividir la palabra por caracteres de forma secuancial de izquierda a derecha. Por ejemplo:\n",
        "\n",
        "\n",
        "```\n",
        "[(\"\", \"oir\"), (\"o\", \"ir\"), (\"oi\", \"r\"), (\"oir\",\"\")]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Ver ejemplo como se muestra en la figura 3\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1hDW7M1hnBfkrV9Qnjap5Yl0F_rcX7v6H\"/>\n",
        " **Figura 3**\n",
        "\n",
        "Este es un paso común a todas las funciones delete_letter, switch_letter, replace_letter, insert_letter"
      ],
      "metadata": {
        "id": "-t-FEmR1QJ00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 2**\n",
        "Generar todas las palabras que resultan de borrar un caracter. Por ejemplo\n",
        "\n",
        "```\n",
        "[\"ir\", \"or\", \"oi\"]\n",
        "```\n",
        "La figura 4 muestra una comparación para realizar el loop de formal generica o usando listh comprehensions\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1XzzMTmdXJEwm3m3E_CSPludJq7_CujGo\"/> **Figura 4**\n",
        "\n"
      ],
      "metadata": {
        "id": "bW9KOK1PRrO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the string/word for which you will generate all possible words\n",
        "                in the vocabulary which have 1 missing character\n",
        "    Output:\n",
        "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
        "    '''\n",
        "\n",
        "    delete_l = []\n",
        "    split_l = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
        "    delete_l = [L + R[1:] for L, R in split_l if R]\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
        "\n",
        "    return  delete_l"
      ],
      "metadata": {
        "id": "mDXDB4h_OF_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_word_l = delete_letter(word=\"oir\", verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otD0Kg3iUkg0",
        "outputId": "ecb73151-e2c7-4039-f0e5-e9af5f6a08c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word oir, \n",
            "split_l = [('', 'oir'), ('o', 'ir'), ('oi', 'r'), ('oir', '')], \n",
            "delete_l = ['ir', 'or', 'oi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Intercambio"
      ],
      "metadata": {
        "id": "eHM7HD6LV78M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instrucciones**\n",
        "Crear la función switch_letter()\n",
        "\n",
        "Por ejemplo, dada la palabras comer, retornar {\"ocmer, comre...\"}, pero NO se intercambian palabras que no sean adyacentes como: \"eomcr\""
      ],
      "metadata": {
        "id": "NQg7cstjWCYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 1** Implementer la función split. Es la misma que en la fución delete_letter()"
      ],
      "metadata": {
        "id": "TgNl5bydWx0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 2** implementar una list comprehension que intercambie letras adyacentes"
      ],
      "metadata": {
        "id": "FRmebMgrW7Ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def switch_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: input string\n",
        "     Output:\n",
        "        switches: a list of all possible strings with one adjacent charater switched\n",
        "    '''\n",
        "\n",
        "    switch_l = []\n",
        "    split_l = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\")\n",
        "\n",
        "    return switch_l"
      ],
      "metadata": {
        "id": "5ps5X9c1UvLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "switch_word_l = switch_letter(word=\"comer\", verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIQM1qJvXYCI",
        "outputId": "1dac76f8-2015-42d2-e69a-8770ccba5c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = comer \n",
            "split_l = [('', 'comer'), ('c', 'omer'), ('co', 'mer'), ('com', 'er'), ('come', 'r'), ('comer', '')] \n",
            "switch_l = ['ocmer', 'cmoer', 'coemr', 'comre']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reemplazar"
      ],
      "metadata": {
        "id": "9m2hW_0rXjuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instrucciones**\n",
        "Crear la función replace_letter()\n",
        "Dada una palabra como fuego, retornar palabras como \"juego, luego, ruego...\""
      ],
      "metadata": {
        "id": "ZzXSrbgSXm47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 1** Implementer la función split. Es la misma que en la fución delete_letter()"
      ],
      "metadata": {
        "id": "a1j1Bp5aYF9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 2** Implementar una List comprehension que reemplace las letras.\n",
        "\n",
        "Puede ser de la forma siguiente:\n",
        "\n",
        "```\n",
        "[f(a, b, c) for a, b in splits if condition for c in string]\n",
        "```\n",
        "\n",
        "Se espera que la palabra original quede incluída. Por ejemplo al reeamplazar la primera letra de \"fuego\" con \"f\" retornará \"fuego\n",
        "\n"
      ],
      "metadata": {
        "id": "E89wLSJLYVDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 3** Remover la palabra original del conjunto de palabras"
      ],
      "metadata": {
        "id": "M7IKH01jZh2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word\n",
        "    Output:\n",
        "        replaces: a list of all possible strings where we replaced one letter from the original word.\n",
        "    '''\n",
        "\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    replace_l = []\n",
        "    split_l = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # turn the set back into a list and sort it, for easier viewing\n",
        "    replace_l = sorted(list(replace_set))\n",
        "\n",
        "\n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")\n",
        "\n",
        "    return replace_l"
      ],
      "metadata": {
        "id": "tZQQq9wBZoaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_l = replace_letter(word='fuego', verbose=True)"
      ],
      "metadata": {
        "id": "7IVLt4g2ZquX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Insertar"
      ],
      "metadata": {
        "id": "x5kyTkviaKA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instrucciones**\n",
        "Crear la función insertar_letter()"
      ],
      "metadata": {
        "id": "oh_ltCtca2-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 1** Implementer la función split. Es la misma que en la fución delete_letter()"
      ],
      "metadata": {
        "id": "J-iD4JAMa-ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 2** Implementar una List comprehensions que inserte las letras. Puede tener la siguiente forma:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "[f(a, b, c) for a, b in splits if conditions for c in string]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "r6dnHcDgbMbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word\n",
        "    Output:\n",
        "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
        "    '''\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_l = []\n",
        "    split_l = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
        "\n",
        "    return insert_l"
      ],
      "metadata": {
        "id": "VqGijHDNaJCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insert_l = insert_letter('ir', True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GFU0QmJbqGX",
        "outputId": "4a34d194-6337-4482-96a2-7afb8d76427f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word ir \n",
            "split_l = [('', 'ir'), ('i', 'r'), ('ir', '')] \n",
            "insert_l = ['air', 'bir', 'cir', 'dir', 'eir', 'fir', 'gir', 'hir', 'iir', 'jir', 'kir', 'lir', 'mir', 'nir', 'oir', 'pir', 'qir', 'rir', 'sir', 'tir', 'uir', 'vir', 'wir', 'xir', 'yir', 'zir', 'iar', 'ibr', 'icr', 'idr', 'ier', 'ifr', 'igr', 'ihr', 'iir', 'ijr', 'ikr', 'ilr', 'imr', 'inr', 'ior', 'ipr', 'iqr', 'irr', 'isr', 'itr', 'iur', 'ivr', 'iwr', 'ixr', 'iyr', 'izr', 'ira', 'irb', 'irc', 'ird', 'ire', 'irf', 'irg', 'irh', 'iri', 'irj', 'irk', 'irl', 'irm', 'irn', 'iro', 'irp', 'irq', 'irr', 'irs', 'irt', 'iru', 'irv', 'irw', 'irx', 'iry', 'irz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combinación de ediciones"
      ],
      "metadata": {
        "id": "qhKdxr1zbKPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función intercambio no es muy común por lo cual se deja la opción de imprimir o no"
      ],
      "metadata": {
        "id": "pSgQwNU1b2v1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##edición de una letra"
      ],
      "metadata": {
        "id": "Z9EPZEpscx4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_one_letter(word, allow_switches = True):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
        "    Output:\n",
        "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
        "    \"\"\"\n",
        "\n",
        "    edit_one_set = set()\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    edit_one_set.update(delete_letter(word))\n",
        "\n",
        "    if allow_switches:\n",
        "        edit_one_set.update(switch_letter(word))\n",
        "\n",
        "    edit_one_set.update(replace_letter(word))\n",
        "\n",
        "    edit_one_set.update(insert_letter(word))\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # return this as a set and not a list\n",
        "    return edit_one_set"
      ],
      "metadata": {
        "id": "FSJpaCr8cSMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_word = \"ir\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "# turn this into a list to sort it, in order to view it\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "print(tmp_edit_one_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3igulKr8caH8",
        "outputId": "7d8c3bee-8100-4b14-b1f3-f32d1c6c592c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['air', 'ar', 'bir', 'br', 'cir', 'cr', 'dir', 'dr', 'eir', 'er', 'fir', 'fr', 'gir', 'gr', 'hir', 'hr', 'i', 'ia', 'iar', 'ib', 'ibr', 'ic', 'icr', 'id', 'idr', 'ie', 'ier', 'if', 'ifr', 'ig', 'igr', 'ih', 'ihr', 'ii', 'iir', 'ij', 'ijr', 'ik', 'ikr', 'il', 'ilr', 'im', 'imr', 'in', 'inr', 'io', 'ior', 'ip', 'ipr', 'iq', 'iqr', 'ira', 'irb', 'irc', 'ird', 'ire', 'irf', 'irg', 'irh', 'iri', 'irj', 'irk', 'irl', 'irm', 'irn', 'iro', 'irp', 'irq', 'irr', 'irs', 'irt', 'iru', 'irv', 'irw', 'irx', 'iry', 'irz', 'is', 'isr', 'it', 'itr', 'iu', 'iur', 'iv', 'ivr', 'iw', 'iwr', 'ix', 'ixr', 'iy', 'iyr', 'iz', 'izr', 'jir', 'jr', 'kir', 'kr', 'lir', 'lr', 'mir', 'mr', 'nir', 'nr', 'oir', 'or', 'pir', 'pr', 'qir', 'qr', 'r', 'ri', 'rir', 'rr', 'sir', 'sr', 'tir', 'tr', 'uir', 'ur', 'vir', 'vr', 'wir', 'wr', 'xir', 'xr', 'yir', 'yr', 'zir', 'zr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##edición de dos letras"
      ],
      "metadata": {
        "id": "6hBba8CZc0mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_two_letters(word, allow_switches = True):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word\n",
        "    Output:\n",
        "        edit_two_set: a set of strings with all possible two edits\n",
        "    '''\n",
        "\n",
        "    edit_two_set = set()\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    one_set = edit_one_letter(word, allow_switches = allow_switches)\n",
        "    for word in one_set:\n",
        "        if word:\n",
        "            edit_two = edit_one_letter(word, allow_switches = allow_switches)\n",
        "            edit_two_set.update(edit_two)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # return this as a set instead of a list\n",
        "    return set(edit_two_set)"
      ],
      "metadata": {
        "id": "4CmF6Et6c2kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(tmp_edit_two_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTk-QmhEdAaD",
        "outputId": "c8e990d6-f96d-4dda-ec5a-de90274e2253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag', 'aah', 'aai', 'aaj', 'aak', 'aal', 'aam', 'aan', 'aao', 'aap', 'aaq', 'aar', 'aas', 'aat', 'aau', 'aav', 'aaw', 'aax', 'aay', 'aaz', 'ab', 'aba', 'abb', 'abc', 'abd', 'abe', 'abf', 'abg', 'abh', 'abi', 'abj', 'abk', 'abl', 'abm', 'abn', 'abo', 'abp', 'abq', 'abr', 'abs', 'abt', 'abu', 'abv', 'abw', 'abx', 'aby', 'abz', 'ac', 'aca', 'acb', 'acc', 'acd', 'ace', 'acf', 'acg', 'ach', 'aci', 'acj', 'ack', 'acl', 'acm', 'acn', 'aco', 'acp', 'acq', 'acr', 'acs', 'act', 'acu', 'acv', 'acw', 'acx', 'acy', 'acz', 'ad', 'ada', 'adb', 'adc', 'add', 'ade', 'adf', 'adg', 'adh', 'adi', 'adj', 'adk', 'adl', 'adm', 'adn', 'ado', 'adp', 'adq', 'adr', 'ads', 'adt', 'adu', 'adv', 'adw', 'adx', 'ady', 'adz', 'ae', 'aea', 'aeb', 'aec', 'aed', 'aee', 'aef', 'aeg', 'aeh', 'aei', 'aej', 'aek', 'ael', 'aem', 'aen', 'aeo', 'aep', 'aeq', 'aer', 'aes', 'aet', 'aeu', 'aev', 'aew', 'aex', 'aey', 'aez', 'af', 'afa', 'afb', 'afc', 'afd', 'afe', 'aff', 'afg', 'afh', 'afi', 'afj', 'afk', 'afl', 'afm', 'afn', 'afo', 'afp', 'afq', 'afr', 'afs', 'aft', 'afu', 'afv', 'afw', 'afx', 'afy', 'afz', 'ag', 'aga', 'agb', 'agc', 'agd', 'age', 'agf', 'agg', 'agh', 'agi', 'agj', 'agk', 'agl', 'agm', 'agn', 'ago', 'agp', 'agq', 'agr', 'ags', 'agt', 'agu', 'agv', 'agw', 'agx', 'agy', 'agz', 'ah', 'aha', 'ahb', 'ahc', 'ahd', 'ahe', 'ahf', 'ahg', 'ahh', 'ahi', 'ahj', 'ahk', 'ahl', 'ahm', 'ahn', 'aho', 'ahp', 'ahq', 'ahr', 'ahs', 'aht', 'ahu', 'ahv', 'ahw', 'ahx', 'ahy', 'ahz', 'ai', 'aia', 'aib', 'aic', 'aid', 'aie', 'aif', 'aig', 'aih', 'aii', 'aij', 'aik', 'ail', 'aim', 'ain', 'aio', 'aip', 'aiq', 'air', 'ais', 'ait', 'aiu', 'aiv', 'aiw', 'aix', 'aiy', 'aiz', 'aj', 'aja', 'ajb', 'ajc', 'ajd', 'aje', 'ajf', 'ajg', 'ajh', 'aji', 'ajj', 'ajk', 'ajl', 'ajm', 'ajn', 'ajo', 'ajp', 'ajq', 'ajr', 'ajs', 'ajt', 'aju', 'ajv', 'ajw', 'ajx', 'ajy', 'ajz', 'ak', 'aka', 'akb', 'akc', 'akd', 'ake', 'akf', 'akg', 'akh', 'aki', 'akj', 'akk', 'akl', 'akm', 'akn', 'ako', 'akp', 'akq', 'akr', 'aks', 'akt', 'aku', 'akv', 'akw', 'akx', 'aky', 'akz', 'al', 'ala', 'alb', 'alc', 'ald', 'ale', 'alf', 'alg', 'alh', 'ali', 'alj', 'alk', 'all', 'alm', 'aln', 'alo', 'alp', 'alq', 'alr', 'als', 'alt', 'alu', 'alv', 'alw', 'alx', 'aly', 'alz', 'am', 'ama', 'amb', 'amc', 'amd', 'ame', 'amf', 'amg', 'amh', 'ami', 'amj', 'amk', 'aml', 'amm', 'amn', 'amo', 'amp', 'amq', 'amr', 'ams', 'amt', 'amu', 'amv', 'amw', 'amx', 'amy', 'amz', 'an', 'ana', 'anb', 'anc', 'and', 'ane', 'anf', 'ang', 'anh', 'ani', 'anj', 'ank', 'anl', 'anm', 'ann', 'ano', 'anp', 'anq', 'anr', 'ans', 'ant', 'anu', 'anv', 'anw', 'anx', 'any', 'anz', 'ao', 'aoa', 'aob', 'aoc', 'aod', 'aoe', 'aof', 'aog', 'aoh', 'aoi', 'aoj', 'aok', 'aol', 'aom', 'aon', 'aoo', 'aop', 'aoq', 'aor', 'aos', 'aot', 'aou', 'aov', 'aow', 'aox', 'aoy', 'aoz', 'ap', 'apa', 'apb', 'apc', 'apd', 'ape', 'apf', 'apg', 'aph', 'api', 'apj', 'apk', 'apl', 'apm', 'apn', 'apo', 'app', 'apq', 'apr', 'aps', 'apt', 'apu', 'apv', 'apw', 'apx', 'apy', 'apz', 'aq', 'aqa', 'aqb', 'aqc', 'aqd', 'aqe', 'aqf', 'aqg', 'aqh', 'aqi', 'aqj', 'aqk', 'aql', 'aqm', 'aqn', 'aqo', 'aqp', 'aqq', 'aqr', 'aqs', 'aqt', 'aqu', 'aqv', 'aqw', 'aqx', 'aqy', 'aqz', 'ar', 'ara', 'arb', 'arc', 'ard', 'are', 'arf', 'arg', 'arh', 'ari', 'arj', 'ark', 'arl', 'arm', 'arn', 'aro', 'arp', 'arq', 'arr', 'ars', 'art', 'aru', 'arv', 'arw', 'arx', 'ary', 'arz', 'as', 'asa', 'asb', 'asc', 'asd', 'ase', 'asf', 'asg', 'ash', 'asi', 'asj', 'ask', 'asl', 'asm', 'asn', 'aso', 'asp', 'asq', 'asr', 'ass', 'ast', 'asu', 'asv', 'asw', 'asx', 'asy', 'asz', 'at', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aua', 'aub', 'auc', 'aud', 'aue', 'auf', 'aug', 'auh', 'aui', 'auj', 'auk', 'aul', 'aum', 'aun', 'auo', 'aup', 'auq', 'aur', 'aus', 'aut', 'auu', 'auv', 'auw', 'aux', 'auy', 'auz', 'av', 'ava', 'avb', 'avc', 'avd', 'ave', 'avf', 'avg', 'avh', 'avi', 'avj', 'avk', 'avl', 'avm', 'avn', 'avo', 'avp', 'avq', 'avr', 'avs', 'avt', 'avu', 'avv', 'avw', 'avx', 'avy', 'avz', 'aw', 'awa', 'awb', 'awc', 'awd', 'awe', 'awf', 'awg', 'awh', 'awi', 'awj', 'awk', 'awl', 'awm', 'awn', 'awo', 'awp', 'awq', 'awr', 'aws', 'awt', 'awu', 'awv', 'aww', 'awx', 'awy', 'awz', 'ax', 'axa', 'axb', 'axc', 'axd', 'axe', 'axf', 'axg', 'axh', 'axi', 'axj', 'axk', 'axl', 'axm', 'axn', 'axo', 'axp', 'axq', 'axr', 'axs', 'axt', 'axu', 'axv', 'axw', 'axx', 'axy', 'axz', 'ay', 'aya', 'ayb', 'ayc', 'ayd', 'aye', 'ayf', 'ayg', 'ayh', 'ayi', 'ayj', 'ayk', 'ayl', 'aym', 'ayn', 'ayo', 'ayp', 'ayq', 'ayr', 'ays', 'ayt', 'ayu', 'ayv', 'ayw', 'ayx', 'ayy', 'ayz', 'az', 'aza', 'azb', 'azc', 'azd', 'aze', 'azf', 'azg', 'azh', 'azi', 'azj', 'azk', 'azl', 'azm', 'azn', 'azo', 'azp', 'azq', 'azr', 'azs', 'azt', 'azu', 'azv', 'azw', 'azx', 'azy', 'azz', 'b', 'ba', 'baa', 'bab', 'bac', 'bad', 'bae', 'baf', 'bag', 'bah', 'bai', 'baj', 'bak', 'bal', 'bam', 'ban', 'bao', 'bap', 'baq', 'bar', 'bas', 'bat', 'bau', 'bav', 'baw', 'bax', 'bay', 'baz', 'bb', 'bba', 'bc', 'bca', 'bd', 'bda', 'be', 'bea', 'bf', 'bfa', 'bg', 'bga', 'bh', 'bha', 'bi', 'bia', 'bj', 'bja', 'bk', 'bka', 'bl', 'bla', 'bm', 'bma', 'bn', 'bna', 'bo', 'boa', 'bp', 'bpa', 'bq', 'bqa', 'br', 'bra', 'bs', 'bsa', 'bt', 'bta', 'bu', 'bua', 'bv', 'bva', 'bw', 'bwa', 'bx', 'bxa', 'by', 'bya', 'bz', 'bza', 'c', 'ca', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'can', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cb', 'cba', 'cc', 'cca', 'cd', 'cda', 'ce', 'cea', 'cf', 'cfa', 'cg', 'cga', 'ch', 'cha', 'ci', 'cia', 'cj', 'cja', 'ck', 'cka', 'cl', 'cla', 'cm', 'cma', 'cn', 'cna', 'co', 'coa', 'cp', 'cpa', 'cq', 'cqa', 'cr', 'cra', 'cs', 'csa', 'ct', 'cta', 'cu', 'cua', 'cv', 'cva', 'cw', 'cwa', 'cx', 'cxa', 'cy', 'cya', 'cz', 'cza', 'd', 'da', 'daa', 'dab', 'dac', 'dad', 'dae', 'daf', 'dag', 'dah', 'dai', 'daj', 'dak', 'dal', 'dam', 'dan', 'dao', 'dap', 'daq', 'dar', 'das', 'dat', 'dau', 'dav', 'daw', 'dax', 'day', 'daz', 'db', 'dba', 'dc', 'dca', 'dd', 'dda', 'de', 'dea', 'df', 'dfa', 'dg', 'dga', 'dh', 'dha', 'di', 'dia', 'dj', 'dja', 'dk', 'dka', 'dl', 'dla', 'dm', 'dma', 'dn', 'dna', 'do', 'doa', 'dp', 'dpa', 'dq', 'dqa', 'dr', 'dra', 'ds', 'dsa', 'dt', 'dta', 'du', 'dua', 'dv', 'dva', 'dw', 'dwa', 'dx', 'dxa', 'dy', 'dya', 'dz', 'dza', 'e', 'ea', 'eaa', 'eab', 'eac', 'ead', 'eae', 'eaf', 'eag', 'eah', 'eai', 'eaj', 'eak', 'eal', 'eam', 'ean', 'eao', 'eap', 'eaq', 'ear', 'eas', 'eat', 'eau', 'eav', 'eaw', 'eax', 'eay', 'eaz', 'eb', 'eba', 'ec', 'eca', 'ed', 'eda', 'ee', 'eea', 'ef', 'efa', 'eg', 'ega', 'eh', 'eha', 'ei', 'eia', 'ej', 'eja', 'ek', 'eka', 'el', 'ela', 'em', 'ema', 'en', 'ena', 'eo', 'eoa', 'ep', 'epa', 'eq', 'eqa', 'er', 'era', 'es', 'esa', 'et', 'eta', 'eu', 'eua', 'ev', 'eva', 'ew', 'ewa', 'ex', 'exa', 'ey', 'eya', 'ez', 'eza', 'f', 'fa', 'faa', 'fab', 'fac', 'fad', 'fae', 'faf', 'fag', 'fah', 'fai', 'faj', 'fak', 'fal', 'fam', 'fan', 'fao', 'fap', 'faq', 'far', 'fas', 'fat', 'fau', 'fav', 'faw', 'fax', 'fay', 'faz', 'fb', 'fba', 'fc', 'fca', 'fd', 'fda', 'fe', 'fea', 'ff', 'ffa', 'fg', 'fga', 'fh', 'fha', 'fi', 'fia', 'fj', 'fja', 'fk', 'fka', 'fl', 'fla', 'fm', 'fma', 'fn', 'fna', 'fo', 'foa', 'fp', 'fpa', 'fq', 'fqa', 'fr', 'fra', 'fs', 'fsa', 'ft', 'fta', 'fu', 'fua', 'fv', 'fva', 'fw', 'fwa', 'fx', 'fxa', 'fy', 'fya', 'fz', 'fza', 'g', 'ga', 'gaa', 'gab', 'gac', 'gad', 'gae', 'gaf', 'gag', 'gah', 'gai', 'gaj', 'gak', 'gal', 'gam', 'gan', 'gao', 'gap', 'gaq', 'gar', 'gas', 'gat', 'gau', 'gav', 'gaw', 'gax', 'gay', 'gaz', 'gb', 'gba', 'gc', 'gca', 'gd', 'gda', 'ge', 'gea', 'gf', 'gfa', 'gg', 'gga', 'gh', 'gha', 'gi', 'gia', 'gj', 'gja', 'gk', 'gka', 'gl', 'gla', 'gm', 'gma', 'gn', 'gna', 'go', 'goa', 'gp', 'gpa', 'gq', 'gqa', 'gr', 'gra', 'gs', 'gsa', 'gt', 'gta', 'gu', 'gua', 'gv', 'gva', 'gw', 'gwa', 'gx', 'gxa', 'gy', 'gya', 'gz', 'gza', 'h', 'ha', 'haa', 'hab', 'hac', 'had', 'hae', 'haf', 'hag', 'hah', 'hai', 'haj', 'hak', 'hal', 'ham', 'han', 'hao', 'hap', 'haq', 'har', 'has', 'hat', 'hau', 'hav', 'haw', 'hax', 'hay', 'haz', 'hb', 'hba', 'hc', 'hca', 'hd', 'hda', 'he', 'hea', 'hf', 'hfa', 'hg', 'hga', 'hh', 'hha', 'hi', 'hia', 'hj', 'hja', 'hk', 'hka', 'hl', 'hla', 'hm', 'hma', 'hn', 'hna', 'ho', 'hoa', 'hp', 'hpa', 'hq', 'hqa', 'hr', 'hra', 'hs', 'hsa', 'ht', 'hta', 'hu', 'hua', 'hv', 'hva', 'hw', 'hwa', 'hx', 'hxa', 'hy', 'hya', 'hz', 'hza', 'i', 'ia', 'iaa', 'iab', 'iac', 'iad', 'iae', 'iaf', 'iag', 'iah', 'iai', 'iaj', 'iak', 'ial', 'iam', 'ian', 'iao', 'iap', 'iaq', 'iar', 'ias', 'iat', 'iau', 'iav', 'iaw', 'iax', 'iay', 'iaz', 'ib', 'iba', 'ic', 'ica', 'id', 'ida', 'ie', 'iea', 'if', 'ifa', 'ig', 'iga', 'ih', 'iha', 'ii', 'iia', 'ij', 'ija', 'ik', 'ika', 'il', 'ila', 'im', 'ima', 'in', 'ina', 'io', 'ioa', 'ip', 'ipa', 'iq', 'iqa', 'ir', 'ira', 'is', 'isa', 'it', 'ita', 'iu', 'iua', 'iv', 'iva', 'iw', 'iwa', 'ix', 'ixa', 'iy', 'iya', 'iz', 'iza', 'j', 'ja', 'jaa', 'jab', 'jac', 'jad', 'jae', 'jaf', 'jag', 'jah', 'jai', 'jaj', 'jak', 'jal', 'jam', 'jan', 'jao', 'jap', 'jaq', 'jar', 'jas', 'jat', 'jau', 'jav', 'jaw', 'jax', 'jay', 'jaz', 'jb', 'jba', 'jc', 'jca', 'jd', 'jda', 'je', 'jea', 'jf', 'jfa', 'jg', 'jga', 'jh', 'jha', 'ji', 'jia', 'jj', 'jja', 'jk', 'jka', 'jl', 'jla', 'jm', 'jma', 'jn', 'jna', 'jo', 'joa', 'jp', 'jpa', 'jq', 'jqa', 'jr', 'jra', 'js', 'jsa', 'jt', 'jta', 'ju', 'jua', 'jv', 'jva', 'jw', 'jwa', 'jx', 'jxa', 'jy', 'jya', 'jz', 'jza', 'k', 'ka', 'kaa', 'kab', 'kac', 'kad', 'kae', 'kaf', 'kag', 'kah', 'kai', 'kaj', 'kak', 'kal', 'kam', 'kan', 'kao', 'kap', 'kaq', 'kar', 'kas', 'kat', 'kau', 'kav', 'kaw', 'kax', 'kay', 'kaz', 'kb', 'kba', 'kc', 'kca', 'kd', 'kda', 'ke', 'kea', 'kf', 'kfa', 'kg', 'kga', 'kh', 'kha', 'ki', 'kia', 'kj', 'kja', 'kk', 'kka', 'kl', 'kla', 'km', 'kma', 'kn', 'kna', 'ko', 'koa', 'kp', 'kpa', 'kq', 'kqa', 'kr', 'kra', 'ks', 'ksa', 'kt', 'kta', 'ku', 'kua', 'kv', 'kva', 'kw', 'kwa', 'kx', 'kxa', 'ky', 'kya', 'kz', 'kza', 'l', 'la', 'laa', 'lab', 'lac', 'lad', 'lae', 'laf', 'lag', 'lah', 'lai', 'laj', 'lak', 'lal', 'lam', 'lan', 'lao', 'lap', 'laq', 'lar', 'las', 'lat', 'lau', 'lav', 'law', 'lax', 'lay', 'laz', 'lb', 'lba', 'lc', 'lca', 'ld', 'lda', 'le', 'lea', 'lf', 'lfa', 'lg', 'lga', 'lh', 'lha', 'li', 'lia', 'lj', 'lja', 'lk', 'lka', 'll', 'lla', 'lm', 'lma', 'ln', 'lna', 'lo', 'loa', 'lp', 'lpa', 'lq', 'lqa', 'lr', 'lra', 'ls', 'lsa', 'lt', 'lta', 'lu', 'lua', 'lv', 'lva', 'lw', 'lwa', 'lx', 'lxa', 'ly', 'lya', 'lz', 'lza', 'm', 'ma', 'maa', 'mab', 'mac', 'mad', 'mae', 'maf', 'mag', 'mah', 'mai', 'maj', 'mak', 'mal', 'mam', 'man', 'mao', 'map', 'maq', 'mar', 'mas', 'mat', 'mau', 'mav', 'maw', 'max', 'may', 'maz', 'mb', 'mba', 'mc', 'mca', 'md', 'mda', 'me', 'mea', 'mf', 'mfa', 'mg', 'mga', 'mh', 'mha', 'mi', 'mia', 'mj', 'mja', 'mk', 'mka', 'ml', 'mla', 'mm', 'mma', 'mn', 'mna', 'mo', 'moa', 'mp', 'mpa', 'mq', 'mqa', 'mr', 'mra', 'ms', 'msa', 'mt', 'mta', 'mu', 'mua', 'mv', 'mva', 'mw', 'mwa', 'mx', 'mxa', 'my', 'mya', 'mz', 'mza', 'n', 'na', 'naa', 'nab', 'nac', 'nad', 'nae', 'naf', 'nag', 'nah', 'nai', 'naj', 'nak', 'nal', 'nam', 'nan', 'nao', 'nap', 'naq', 'nar', 'nas', 'nat', 'nau', 'nav', 'naw', 'nax', 'nay', 'naz', 'nb', 'nba', 'nc', 'nca', 'nd', 'nda', 'ne', 'nea', 'nf', 'nfa', 'ng', 'nga', 'nh', 'nha', 'ni', 'nia', 'nj', 'nja', 'nk', 'nka', 'nl', 'nla', 'nm', 'nma', 'nn', 'nna', 'no', 'noa', 'np', 'npa', 'nq', 'nqa', 'nr', 'nra', 'ns', 'nsa', 'nt', 'nta', 'nu', 'nua', 'nv', 'nva', 'nw', 'nwa', 'nx', 'nxa', 'ny', 'nya', 'nz', 'nza', 'o', 'oa', 'oaa', 'oab', 'oac', 'oad', 'oae', 'oaf', 'oag', 'oah', 'oai', 'oaj', 'oak', 'oal', 'oam', 'oan', 'oao', 'oap', 'oaq', 'oar', 'oas', 'oat', 'oau', 'oav', 'oaw', 'oax', 'oay', 'oaz', 'ob', 'oba', 'oc', 'oca', 'od', 'oda', 'oe', 'oea', 'of', 'ofa', 'og', 'oga', 'oh', 'oha', 'oi', 'oia', 'oj', 'oja', 'ok', 'oka', 'ol', 'ola', 'om', 'oma', 'on', 'ona', 'oo', 'ooa', 'op', 'opa', 'oq', 'oqa', 'or', 'ora', 'os', 'osa', 'ot', 'ota', 'ou', 'oua', 'ov', 'ova', 'ow', 'owa', 'ox', 'oxa', 'oy', 'oya', 'oz', 'oza', 'p', 'pa', 'paa', 'pab', 'pac', 'pad', 'pae', 'paf', 'pag', 'pah', 'pai', 'paj', 'pak', 'pal', 'pam', 'pan', 'pao', 'pap', 'paq', 'par', 'pas', 'pat', 'pau', 'pav', 'paw', 'pax', 'pay', 'paz', 'pb', 'pba', 'pc', 'pca', 'pd', 'pda', 'pe', 'pea', 'pf', 'pfa', 'pg', 'pga', 'ph', 'pha', 'pi', 'pia', 'pj', 'pja', 'pk', 'pka', 'pl', 'pla', 'pm', 'pma', 'pn', 'pna', 'po', 'poa', 'pp', 'ppa', 'pq', 'pqa', 'pr', 'pra', 'ps', 'psa', 'pt', 'pta', 'pu', 'pua', 'pv', 'pva', 'pw', 'pwa', 'px', 'pxa', 'py', 'pya', 'pz', 'pza', 'q', 'qa', 'qaa', 'qab', 'qac', 'qad', 'qae', 'qaf', 'qag', 'qah', 'qai', 'qaj', 'qak', 'qal', 'qam', 'qan', 'qao', 'qap', 'qaq', 'qar', 'qas', 'qat', 'qau', 'qav', 'qaw', 'qax', 'qay', 'qaz', 'qb', 'qba', 'qc', 'qca', 'qd', 'qda', 'qe', 'qea', 'qf', 'qfa', 'qg', 'qga', 'qh', 'qha', 'qi', 'qia', 'qj', 'qja', 'qk', 'qka', 'ql', 'qla', 'qm', 'qma', 'qn', 'qna', 'qo', 'qoa', 'qp', 'qpa', 'qq', 'qqa', 'qr', 'qra', 'qs', 'qsa', 'qt', 'qta', 'qu', 'qua', 'qv', 'qva', 'qw', 'qwa', 'qx', 'qxa', 'qy', 'qya', 'qz', 'qza', 'r', 'ra', 'raa', 'rab', 'rac', 'rad', 'rae', 'raf', 'rag', 'rah', 'rai', 'raj', 'rak', 'ral', 'ram', 'ran', 'rao', 'rap', 'raq', 'rar', 'ras', 'rat', 'rau', 'rav', 'raw', 'rax', 'ray', 'raz', 'rb', 'rba', 'rc', 'rca', 'rd', 'rda', 're', 'rea', 'rf', 'rfa', 'rg', 'rga', 'rh', 'rha', 'ri', 'ria', 'rj', 'rja', 'rk', 'rka', 'rl', 'rla', 'rm', 'rma', 'rn', 'rna', 'ro', 'roa', 'rp', 'rpa', 'rq', 'rqa', 'rr', 'rra', 'rs', 'rsa', 'rt', 'rta', 'ru', 'rua', 'rv', 'rva', 'rw', 'rwa', 'rx', 'rxa', 'ry', 'rya', 'rz', 'rza', 's', 'sa', 'saa', 'sab', 'sac', 'sad', 'sae', 'saf', 'sag', 'sah', 'sai', 'saj', 'sak', 'sal', 'sam', 'san', 'sao', 'sap', 'saq', 'sar', 'sas', 'sat', 'sau', 'sav', 'saw', 'sax', 'say', 'saz', 'sb', 'sba', 'sc', 'sca', 'sd', 'sda', 'se', 'sea', 'sf', 'sfa', 'sg', 'sga', 'sh', 'sha', 'si', 'sia', 'sj', 'sja', 'sk', 'ska', 'sl', 'sla', 'sm', 'sma', 'sn', 'sna', 'so', 'soa', 'sp', 'spa', 'sq', 'sqa', 'sr', 'sra', 'ss', 'ssa', 'st', 'sta', 'su', 'sua', 'sv', 'sva', 'sw', 'swa', 'sx', 'sxa', 'sy', 'sya', 'sz', 'sza', 't', 'ta', 'taa', 'tab', 'tac', 'tad', 'tae', 'taf', 'tag', 'tah', 'tai', 'taj', 'tak', 'tal', 'tam', 'tan', 'tao', 'tap', 'taq', 'tar', 'tas', 'tat', 'tau', 'tav', 'taw', 'tax', 'tay', 'taz', 'tb', 'tba', 'tc', 'tca', 'td', 'tda', 'te', 'tea', 'tf', 'tfa', 'tg', 'tga', 'th', 'tha', 'ti', 'tia', 'tj', 'tja', 'tk', 'tka', 'tl', 'tla', 'tm', 'tma', 'tn', 'tna', 'to', 'toa', 'tp', 'tpa', 'tq', 'tqa', 'tr', 'tra', 'ts', 'tsa', 'tt', 'tta', 'tu', 'tua', 'tv', 'tva', 'tw', 'twa', 'tx', 'txa', 'ty', 'tya', 'tz', 'tza', 'u', 'ua', 'uaa', 'uab', 'uac', 'uad', 'uae', 'uaf', 'uag', 'uah', 'uai', 'uaj', 'uak', 'ual', 'uam', 'uan', 'uao', 'uap', 'uaq', 'uar', 'uas', 'uat', 'uau', 'uav', 'uaw', 'uax', 'uay', 'uaz', 'ub', 'uba', 'uc', 'uca', 'ud', 'uda', 'ue', 'uea', 'uf', 'ufa', 'ug', 'uga', 'uh', 'uha', 'ui', 'uia', 'uj', 'uja', 'uk', 'uka', 'ul', 'ula', 'um', 'uma', 'un', 'una', 'uo', 'uoa', 'up', 'upa', 'uq', 'uqa', 'ur', 'ura', 'us', 'usa', 'ut', 'uta', 'uu', 'uua', 'uv', 'uva', 'uw', 'uwa', 'ux', 'uxa', 'uy', 'uya', 'uz', 'uza', 'v', 'va', 'vaa', 'vab', 'vac', 'vad', 'vae', 'vaf', 'vag', 'vah', 'vai', 'vaj', 'vak', 'val', 'vam', 'van', 'vao', 'vap', 'vaq', 'var', 'vas', 'vat', 'vau', 'vav', 'vaw', 'vax', 'vay', 'vaz', 'vb', 'vba', 'vc', 'vca', 'vd', 'vda', 've', 'vea', 'vf', 'vfa', 'vg', 'vga', 'vh', 'vha', 'vi', 'via', 'vj', 'vja', 'vk', 'vka', 'vl', 'vla', 'vm', 'vma', 'vn', 'vna', 'vo', 'voa', 'vp', 'vpa', 'vq', 'vqa', 'vr', 'vra', 'vs', 'vsa', 'vt', 'vta', 'vu', 'vua', 'vv', 'vva', 'vw', 'vwa', 'vx', 'vxa', 'vy', 'vya', 'vz', 'vza', 'w', 'wa', 'waa', 'wab', 'wac', 'wad', 'wae', 'waf', 'wag', 'wah', 'wai', 'waj', 'wak', 'wal', 'wam', 'wan', 'wao', 'wap', 'waq', 'war', 'was', 'wat', 'wau', 'wav', 'waw', 'wax', 'way', 'waz', 'wb', 'wba', 'wc', 'wca', 'wd', 'wda', 'we', 'wea', 'wf', 'wfa', 'wg', 'wga', 'wh', 'wha', 'wi', 'wia', 'wj', 'wja', 'wk', 'wka', 'wl', 'wla', 'wm', 'wma', 'wn', 'wna', 'wo', 'woa', 'wp', 'wpa', 'wq', 'wqa', 'wr', 'wra', 'ws', 'wsa', 'wt', 'wta', 'wu', 'wua', 'wv', 'wva', 'ww', 'wwa', 'wx', 'wxa', 'wy', 'wya', 'wz', 'wza', 'x', 'xa', 'xaa', 'xab', 'xac', 'xad', 'xae', 'xaf', 'xag', 'xah', 'xai', 'xaj', 'xak', 'xal', 'xam', 'xan', 'xao', 'xap', 'xaq', 'xar', 'xas', 'xat', 'xau', 'xav', 'xaw', 'xax', 'xay', 'xaz', 'xb', 'xba', 'xc', 'xca', 'xd', 'xda', 'xe', 'xea', 'xf', 'xfa', 'xg', 'xga', 'xh', 'xha', 'xi', 'xia', 'xj', 'xja', 'xk', 'xka', 'xl', 'xla', 'xm', 'xma', 'xn', 'xna', 'xo', 'xoa', 'xp', 'xpa', 'xq', 'xqa', 'xr', 'xra', 'xs', 'xsa', 'xt', 'xta', 'xu', 'xua', 'xv', 'xva', 'xw', 'xwa', 'xx', 'xxa', 'xy', 'xya', 'xz', 'xza', 'y', 'ya', 'yaa', 'yab', 'yac', 'yad', 'yae', 'yaf', 'yag', 'yah', 'yai', 'yaj', 'yak', 'yal', 'yam', 'yan', 'yao', 'yap', 'yaq', 'yar', 'yas', 'yat', 'yau', 'yav', 'yaw', 'yax', 'yay', 'yaz', 'yb', 'yba', 'yc', 'yca', 'yd', 'yda', 'ye', 'yea', 'yf', 'yfa', 'yg', 'yga', 'yh', 'yha', 'yi', 'yia', 'yj', 'yja', 'yk', 'yka', 'yl', 'yla', 'ym', 'yma', 'yn', 'yna', 'yo', 'yoa', 'yp', 'ypa', 'yq', 'yqa', 'yr', 'yra', 'ys', 'ysa', 'yt', 'yta', 'yu', 'yua', 'yv', 'yva', 'yw', 'ywa', 'yx', 'yxa', 'yy', 'yya', 'yz', 'yza', 'z', 'za', 'zaa', 'zab', 'zac', 'zad', 'zae', 'zaf', 'zag', 'zah', 'zai', 'zaj', 'zak', 'zal', 'zam', 'zan', 'zao', 'zap', 'zaq', 'zar', 'zas', 'zat', 'zau', 'zav', 'zaw', 'zax', 'zay', 'zaz', 'zb', 'zba', 'zc', 'zca', 'zd', 'zda', 'ze', 'zea', 'zf', 'zfa', 'zg', 'zga', 'zh', 'zha', 'zi', 'zia', 'zj', 'zja', 'zk', 'zka', 'zl', 'zla', 'zm', 'zma', 'zn', 'zna', 'zo', 'zoa', 'zp', 'zpa', 'zq', 'zqa', 'zr', 'zra', 'zs', 'zsa', 'zt', 'zta', 'zu', 'zua', 'zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sugerencias de corrección"
      ],
      "metadata": {
        "id": "AlhZ0CpvdKHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: a user entered string to check for suggestions\n",
        "        probs: a dictionary that maps each word to its probability in the corpus\n",
        "        vocab: a set containing all the vocabulary\n",
        "        n: number of possible word corrections you want returned in the dictionary\n",
        "    Output:\n",
        "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
        "    '''\n",
        "\n",
        "    suggestions = []\n",
        "    n_best = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    #Step 1: create suggestions as described above\n",
        "\n",
        "\n",
        "    #Step 2: determine probability of suggestions\n",
        "\n",
        "    #Step 3: Get all your best words and return the most probable top n_suggested words as n_best\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "metadata": {
        "id": "RI9I4OBidJWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_word = 'dolcinea'\n",
        "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
        "\n",
        "print(\"data type of corrections {}\".format(type(tmp_corrections)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UKkl0bvdQKq",
        "outputId": "79977a6d-b8f7-48f2-89e3-1f556975a679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entered word =  dolcinea \n",
            "suggestions =  ['dulcinea']\n",
            "word 0: dulcinea, probability 0.000734\n",
            "data type of corrections <class 'list'>\n"
          ]
        }
      ]
    }
  ]
}